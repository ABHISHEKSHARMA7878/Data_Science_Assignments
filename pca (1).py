# -*- coding: utf-8 -*-
"""PCA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gt7A0EDtO1lWLc1yLnJcFSlrVZ95CCvz
"""

import pandas as pd
df = pd.read_csv("wine.csv")
df

df.describe()

df.isnull().sum()

df.dtypes

import matplotlib.pyplot as plt
import seaborn as sns

# Histograms for all numerical columns
df.hist(bins=10, figsize=(15, 10))
plt.tight_layout()
plt.show()

# Box plots for numerical features
plt.figure(figsize=(15, 10))
sns.boxplot(data=df)
plt.xticks(rotation=90)
plt.show()

# Density plots for numerical features
for column in df.select_dtypes(include=['float', 'int']).columns:
  plt.figure()
  sns.kdeplot(df[column])
  plt.title(f'Density Plot of {column}')
  plt.show()

# Calculate the correlation matrix
corr_matrix = df.corr()

# Plot the heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.show()

from sklearn.preprocessing import StandardScaler


# Separate the features and target
X = df.drop('Type', axis=1)

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

from sklearn.decomposition import PCA
import numpy as np

# Apply PCA
pca = PCA()
pca.fit(X_scaled)

# Calculate the cumulative explained variance
cumulative_variance = np.cumsum(pca.explained_variance_ratio_)

# Plot the scree plot
plt.figure(figsize=(10, 6))
plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o')
plt.xlabel('Number of Principal Components')
plt.ylabel('Cumulative Explained Variance')
plt.show()

# Transsform the dataset into the principle components
pca_optimal = PCA(n_components=3)
X_pca = pca_optimal.fit_transform(X_scaled)
X_pca

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score

# Apply K-means clustering
kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(X)
clusters

silhouette = silhouette_score(X, clusters)
davies_bouldin = davies_bouldin_score(X, clusters)
davies_bouldin

# Visualize the Clustering Results

plt.figure(figsize=(10, 6))
sns.scatterplot(x=X['Alcohol'], y=X['Malic'], hue=clusters, palette='viridis')
plt.title('K-means Clustering (Original Data)')
plt.show()

# Clustring with PCA Data

kmeans_pca = KMeans(n_clusters=3, random_state=42)
clusters_pca = kmeans_pca.fit_predict(X_pca)
clusters_pca

# Evaluate clustering performance

silhouette_pca = silhouette_score(X_pca, clusters_pca)
davies_bouldin_pca = davies_bouldin_score(X_pca, clusters_pca)

# Visualize Clustering Results on PCA Data
plt.figure(figsize=(10, 6))
sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=clusters_pca, palette='viridis')
plt.title('K-means Clustering (PCA Data)')
plt.show()

# Compare Clustering Results

print("Original Data:")
print("Silhouette Score:", silhouette)
print("Davies-Bouldin Index:", davies_bouldin)
print("\nPCA-Transformed Data:")
print("Silhouette Score:", silhouette_pca)
print("Davies-Bouldin Index:", davies_bouldin_pca)