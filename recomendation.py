# -*- coding: utf-8 -*-
"""Recomendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nD_svetYGgLNvPUz4VcEBrJGjhpfCQWO
"""

import pandas as pd

# Load the dataset
df = pd.read_csv('anime.csv')
df.head()

df.info()

df.isnull().sum()

# Fill missing values in 'rating' with the mean
df['rating'].fillna(df['rating'].mean(), inplace=True)

# Fill missing values in 'genre' with the most frequent value
df['genre'].fillna(df['genre'].mode()[0], inplace=True)

# Fill missing values in 'type' with the most frequent value
df['type'].fillna(df['type'].mode()[0], inplace=True)

df.isnull().sum()

from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer, StandardScaler

# Encode 'type' with LabelEncoder
le = LabelEncoder()
df['type'] = le.fit_transform(df['type'])

mlb = MultiLabelBinarizer()
genre_encoded = mlb.fit_transform(df['genre'])
genre_df = pd.DataFrame(genre_encoded, columns=mlb.classes_, index=df.index)
df = pd.concat([df, genre_df], axis=1)
df.drop('genre', axis=1, inplace=True)

genre_df.head()

genre_df.shape

df['episodes'].replace('Unknown', pd.NA, inplace=True)
df['episodes'].fillna(df['episodes'].median(), inplace=True)
df['episodes'] = pd.to_numeric(df['episodes'])

# Initialize the scaler
scaler = StandardScaler()

# Scale numerical columns
df[['rating', 'episodes', 'members']] = scaler.fit_transform(df[['rating', 'episodes', 'members']])
df.head()

from sklearn.metrics.pairwise import cosine_similarity

def recommend_anime(anime_name, df, top_n=10):
      # Get the index of the anime
      index = df[df['name'] == anime_name].index[0]

      # Calculate cosine similarity with all other anime
      similarity_scores = cosine_similarity(df.iloc[index, 2:].values.reshape(1, -1), df.iloc[:, 2:].values)

      # Sort anime by similarity score
      sorted_indices = similarity_scores.argsort()[0][::-1]

      # Return the top N most similar anime (excluding the input anime)
      recommended_anime = []
      for i in sorted_indices[1:top_n + 1]:
        recommended_anime.append(df.iloc[i]['name'])

      return recommended_anime
similar_anime = recommend_anime('Naruto', df)
similar_anime

def recommend_anime(anime_name, df, top_n=10, threshold=0.5):
  # Get the index of the anime
  index = df[df['name'] == anime_name].index[0]

  # Calculate cosine similarity with all other anime
  similarity_scores = cosine_similarity(df.iloc[index, 2:].values.reshape(1, -1), df.iloc[:, 2:].values)

  # Apply threshold to similarity scores
  similarity_scores[similarity_scores < threshold] = 0

  # Sort anime by similarity score
  sorted_indices = similarity_scores.argsort()[0][::-1]

  # Return the top N most similar anime (excluding the input anime)
  recommended_anime = []
  for i in sorted_indices[1:top_n + 1]:
    recommended_anime.append(df.iloc[i]['name'])

  return recommended_anime

# Experiment with different threshold values = 0.8
similar_anime_high_threshold = recommend_anime('Naruto', df, threshold=0.8)
similar_anime_high_threshold

# Experiment with different threshold values = 0.3
similar_anime_low_threshold = recommend_anime('Naruto', df, threshold=0.3)
similar_anime_low_threshold

from sklearn.model_selection import train_test_split

X = df.drop(['name'], axis=1)
Y = df['rating']

# Split the data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

from sklearn.metrics import precision_score, recall_score, f1_score

def evaluate_recommendations(df, test_users, top_n=10, threshold=0.5):
    all_precision = []
    all_recall = []
    all_f1 = []

    # Initialize lists to store all recommended and relevant anime across users
    all_recommended = []
    all_relevant = []

    for user_index in test_users:
        # Get the anime watched by the user (in this case, we treat it as the target for recommendations)
        watched_anime = df.iloc[user_index]['name']

        # Generate recommendations for the watched anime
        recommended_anime = recommend_anime(watched_anime, df, top_n, threshold)

        # Assume some ground truth-relevant anime for the user (replace with actual ground truth)
        relevant_anime = ['One Piece', 'Bleach']  # Example of relevant anime

        # Convert lists to sets for efficient comparison
        recommended_set = set(recommended_anime)
        relevant_set = set(relevant_anime)

        # Calculate precision, recall, and F1-score for this user's recommendations
        true_positives = len(recommended_set & relevant_set)
        false_positives = len(recommended_set - relevant_set)
        false_negatives = len(relevant_set - recommended_set)

        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

        # Store the metrics for this user
        all_precision.append(precision)
        all_recall.append(recall)
        all_f1.append(f1)

    # Return the average metrics
    return {
        'precision': sum(all_precision) / len(all_precision),
        'recall': sum(all_recall) / len(all_recall),
        'f1_score': sum(all_f1) / len(all_f1)
    }

# Example usage:
# Assuming you have a list of test user indices
test_users = [10, 25, 50]

metrics = evaluate_recommendations(df, test_users)
print("Precision:", metrics['precision'])
print("Recall:", metrics['recall'])
print("F1-score:", metrics['f1_score'])

# prompt: I need to Analyze the performance of the recommendation system and identify areas of improvement.

# Experiment with different thresholds and top-N values
thresholds = [0.3, 0.5, 0.7, 0.9]
top_ns = [5, 10, 15, 20]

results = []
for threshold in thresholds:
  for top_n in top_ns:
    metrics = evaluate_recommendations(df, test_users, top_n=top_n, threshold=threshold)
    results.append({
        'threshold': threshold,
        'top_n': top_n,
        'precision': metrics['precision'],
        'recall': metrics['recall'],
        'f1_score': metrics['f1_score']
    })

# Analyze the results (e.g., plot them)
results_df = pd.DataFrame(results)

import matplotlib.pyplot as plt
import seaborn as sns

# Plot F1-score as a function of threshold and top-N
plt.figure(figsize=(10, 6))
sns.lineplot(data=results_df, x='threshold', y='f1_score', hue='top_n')
plt.title('F1-score vs. Threshold and Top-N')
plt.xlabel('Threshold')
plt.ylabel('F1-score')
plt.show()

