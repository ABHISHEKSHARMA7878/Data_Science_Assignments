# -*- coding: utf-8 -*-
"""Clustering .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d1NE0K9PJ3c0--7dwdhYTdklrS46ZV9L
"""

# import data File
import pandas as pd
df = pd.read_csv("EastWestAirlines.csv")
df

df.info()  # check the informations

df.shape

df.isnull().sum()  # Check missing value

# Numerical column
num_col = df.select_dtypes(include=['number']).columns
df[num_col] = df[num_col].fillna(df[num_col].mean())

# Find the IQR(Interquartile range)
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1
df_out = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]

# Apply the preprocessing
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaled_features = scaler.fit_transform(df_out.select_dtypes(include=['number']))
df_scaled = pd.DataFrame(scaled_features, columns=df_out.select_dtypes(include=['number']).columns)

# Data Visualication
import matplotlib.pyplot as plt
import seaborn as sns

# Histogram
df_scaled.hist(figsize=(15,10))
plt.show()

# Box plot
df_scaled.boxplot(figsize=(15,10))
plt.show()

corr_matrix = df_scaled.corr()

# Heatmap

plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.show()

# Pair plot

sns.pairplot(df_scaled)
plt.show()

# Identify the potential culusters
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans

# Perform PCA
pca = PCA(n_components=2)
pca_result = pca.fit_transform(df_scaled)

# Visualize PCA result
plt.scatter(pca_result[:, 0], pca_result[:, 1])
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA Visualization')
plt.show()

# K-means clustering
kmeans = KMeans(n_clusters=3, n_init=10)  # Set n_init explicitly
clusters = kmeans.fit_predict(df_scaled)

# K-means Clustering Visualization
plt.scatter(pca_result[:, 0], pca_result[:, 1], c=clusters)
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('K-means Clustering Visualization')
plt.show()

# Implement Clustering Algorithms
from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN

# K Means Clustering
kmeans = KMeans(n_clusters=5, n_init=10, random_state=42)
kmeans_labels = kmeans.fit_predict(df_scaled)

# Hierarchical Clustering
hierarchical = AgglomerativeClustering(n_clusters=5)
hierarchical_labels = hierarchical.fit_predict(df_scaled)

# DBSCAN Clustering
dbscan = DBSCAN(eps=0.5, min_samples=5)
dbscan_labels = dbscan.fit_predict(df_scaled)

df_scaled['KMeans_Cluster'] = kmeans_labels
df_scaled['Hierarchical_Cluster'] = hierarchical_labels
df_scaled['DBSCAN_Cluster'] = dbscan_labels

df_scaled.head()

from sklearn.metrics import silhouette_score

# Experiment with Hierarchical Clustering
linkage_methods = ['ward', 'complete', 'average', 'single']
best_silhouette = -1
best_linkage = None

for linkage in linkage_methods:
  hierarchical = AgglomerativeClustering(n_clusters=5, linkage=linkage)
  hierarchical_labels = hierarchical.fit_predict(df_scaled)
  silhouette_avg = silhouette_score(df_scaled, hierarchical_labels)
  print(f"Silhouette score for linkage {linkage}: {silhouette_avg}")

  if silhouette_avg > best_silhouette:
    best_silhouette = silhouette_avg
    best_linkage = linkage

print(f"\nBest linkage method: {best_linkage} with silhouette score: {best_silhouette}")

# Experiment with K-Means (Elbow Method)
inertia = []
k_range = range(1, 11)  # Try different K values

for k in k_range:
    kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)  # Set n_init explicitly
    kmeans.fit(df_scaled)
    inertia.append(kmeans.inertia_)

plt.plot(k_range, inertia, 'bx-')
plt.xlabel('Number of Clusters (K)')
plt.ylabel('Inertia')
plt.title('Elbow Method for Optimal K')
plt.show()

# Experiment with DBSCAN
eps_values = [0.3, 0.5, 0.7, 1.0]
min_samples_values = [3, 5, 7, 10]

for eps in eps_values:
  for min_samples in min_samples_values:
    dbscan = DBSCAN(eps=eps, min_samples=min_samples)
    dbscan_labels = dbscan.fit_predict(df_scaled)

    # Check if there are any clusters formed
    if len(set(dbscan_labels)) > 1:
      silhouette_avg = silhouette_score(df_scaled, dbscan_labels)
      print(f"Silhouette score for eps={eps}, min_samples={min_samples}: {silhouette_avg}")
    else:
      print(f"No clusters formed for eps={eps}, min_samples={min_samples}")

# Analyze K-Means Clusters
kmeans_clusters = df_scaled.groupby('KMeans_Cluster').mean()
kmeans_clusters
# Analyze the mean values of features for each K-Means cluster
# Interpret and comment on the characteristics of each K-Means cluster:
# Example:
# - Cluster 0: High average balance, frequent flyers, etc.  (Potential high-value customers)
# - Cluster 1: Low engagement, infrequent flyers, etc. (Potential churn risk)

# Analyze Hierarchical Clusters

hierarchical_clusters = df_scaled.groupby('Hierarchical_Cluster').mean()
hierarchical_clusters
# Analyze the mean values of features for each Hierarchical cluster
# Interpret and comment on the characteristics of each Hierarchical cluster:
# Example:
# - Cluster 2: Price-sensitive customers, respond well to promotions, etc.
# - Cluster 4: Loyal customers, high lifetime value, etc.

# Analyze DBSCAN Clusters

dbscan_clusters = df_scaled[df_scaled['DBSCAN_Cluster'] != -1].groupby('DBSCAN_Cluster').mean()
dbscan_clusters
# Analyze the mean values of features for each DBSCAN cluster
# Interpret and comment on the characteristics of each DBSCAN cluster:
# Example:
# - Cluster 1: Customers with unique behavior, might require special attention.

# Visualize K-Means Clusters
plt.scatter(pca_result[:, 0], pca_result[:, 1], c=kmeans_labels)
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('K-means Clustering Visualization')
plt.show()

# Visualize Hierarchical Clusters
plt.scatter(pca_result[:, 0], pca_result[:, 1], c=hierarchical_labels)
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('Hierarchical Clustering Visualization')
plt.show()

# Visualize DBSCAN Clusters (consider noise points)
plt.scatter(pca_result[:, 0], pca_result[:, 1], c=dbscan_labels)
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('DBSCAN Clustering Visualization')
plt.show()

# Visualize K-Means Clusters
plt.scatter(pca_result[:, 0], pca_result[:, 1], c=kmeans_labels, cmap='viridis')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('K-means Clustering Visualization')
plt.colorbar(label='Cluster')
plt.show()

# Visualize Hierarchical Clusters
plt.scatter(pca_result[:, 0], pca_result[:, 1], c=hierarchical_labels, cmap='plasma')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('Hierarchical Clustering Visualization')
plt.colorbar(label='Cluster')
plt.show()

# Visualize DBSCAN Clusters
plt.scatter(pca_result[:, 0], pca_result[:, 1], c=dbscan_labels, cmap='coolwarm')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('DBSCAN Clustering Visualization')
plt.colorbar(label='Cluster')
plt.show()

# Evaluation and Performance Metrics:

from sklearn.metrics import silhouette_score

# Calculate Silhouette Score for K-Means
kmeans_silhouette = silhouette_score(df_scaled, kmeans_labels)
print(f"Silhouette Score for K-Means: {kmeans_silhouette}")

# Calculate Silhouette Score for DBSCAN (excluding noise points)
dbscan_labels_no_noise = dbscan_labels[dbscan_labels != -1]
df_scaled_no_noise = df_scaled[dbscan_labels != -1]
if len(set(dbscan_labels_no_noise)) > 1:  # Check if there are clusters after removing noise
  dbscan_silhouette = silhouette_score(df_scaled_no_noise, dbscan_labels_no_noise)
  print(f"Silhouette Score for DBSCAN (excluding noise): {dbscan_silhouette}")
else:
  print("Cannot calculate Silhouette Score for DBSCAN as there are no clusters after removing noise.")

