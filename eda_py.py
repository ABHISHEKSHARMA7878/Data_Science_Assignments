# -*- coding: utf-8 -*-
"""EDA.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FlEdQbn6hshuLWDzxo6wLRHgEQwiswL3
"""



"""# Data Cleaning and Preparation"""

import pandas as pd

# Load the dataset into a DataFrame
df = pd.read_csv('/content/Cardiotocographic.csv')

# Display the first few rows of the dataset
df.head()

# Check for missing values
missing_values = df.isnull().sum()

# If missing values are found, decide how to handle them (e.g., mean/median imputation or dropping rows)
df.fillna(df.median(), inplace=True)  # Example of median imputation

# Verify missing values are handled
df.isnull().sum()

# Convert any numerical values stored as strings to numeric types
df['LB'] = pd.to_numeric(df['LB'], errors='coerce')
df['AC'] = pd.to_numeric(df['AC'], errors='coerce')
# Repeat for other columns if necessary

# Verify data types
df.dtypes

import numpy as np

# Identify outliers using the IQR method
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1

# Filter out the outliers
df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]

# Display the cleaned DataFrame
df.describe()

"""# Statistical Summary"""

# Summary statistics for each variable
stat_summary = df.describe()

# Add median to the summary
stat_summary.loc['median'] = df.median()

# Display the summary
stat_summary

# Identify key statistics
df_skewness = df.skew()
df_kurtosis = df.kurtosis()

#Print variables with high skewness
high_skew = df_skewness[df_skewness.abs() > 1]
high_skew

"""# Data Visualization"""

import matplotlib.pyplot as plt
import seaborn as sns

# Histogram for 'LB'
plt.figure(figsize=(10, 6))
sns.histplot(df['LB'], kde=True)
plt.title('Distribution of Baseline Fetal Heart Rate (LB)')
plt.show()

# Boxplot for 'AC'
plt.figure(figsize=(10, 6))
sns.boxplot(x=df['AC'])
plt.title('Boxplot of Accelerations (AC)')
plt.show()

# Example: Frequency of 'AC' categories if categorized
df['AC_cat'] = pd.cut(df['AC'], bins=[0, 5, 10, 15, 20], labels=['0-5', '5-10', '10-15', '15-20'])
df['AC_cat'].value_counts().plot(kind='bar', figsize=(10, 6))
plt.title('Frequency of Accelerations (AC) Categories')
plt.show()

# Ensure 'AC_cat' is not included in numeric operations
df_numeric = df.select_dtypes(include=[np.number])

# Scatter plot for 'LB' vs 'UC'
plt.figure(figsize=(10, 6))
sns.scatterplot(x='LB', y='UC', data=df)
plt.title('Scatter Plot of LB vs UC')
plt.show()

# Correlation heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(df_numeric.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

# Pair plot
sns.pairplot(df)
plt.show()

# Violin plot for 'LB' by 'UC' categories
plt.figure(figsize=(10, 6))
sns.violinplot(x='UC', y='LB', data=df)
plt.title('Violin Plot of LB by UC')
plt.show()

"""# Pattern Recognition and Insights"""

# Calculate correlations and identify strong correlations
correlations = df_numeric.corr()
strong_corr = correlations[(correlations > 0.7) & (correlations < 1)]

# Discuss potential implications
print("Strong correlations found:\n", strong_corr)

# Example: If temporal data is available, analyze trends over time
# Assuming there's a 'Time' column for temporal analysis
#df['Time'] = pd.to_datetime(df['Time'])
#df.set_index('Time').resample('D').mean().plot(figsize=(10, 6))
#plt.title('Daily Average of Variables Over Time')
#plt.show()

# Summarize the key
summary = """
Key Insights:
1. Variables X and Y show a strong positive correlation, suggesting a potential relationship between ...
2. Variable Z has high variability, indicating ...
3. The distribution of LB is skewed, which might ...
"""
print(summary)

# Discuss how findings could impact further analysis or decisions
impact = """
These findings suggest that further analysis should focus on
The strong correlation between X and Y indicates a potential
"""
print(impact)

